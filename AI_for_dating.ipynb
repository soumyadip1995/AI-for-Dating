{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI for dating.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyadip1995/AI-for-Dating/blob/master/AI_for_dating.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9eHgHnER7Nt",
        "colab_type": "text"
      },
      "source": [
        "# AI in the Dating World\n",
        "\n",
        "\n",
        "![alt text](http://images.hellogiggles.com/uploads/2016/10/28032253/big-bang-theory-penny-leonard-just-like-friends-ross-and-rachel.jpg)\n",
        "\n",
        "\n",
        "Read The Full Blog Post [here](https://soumyadip1995.blogspot.com/2019/06/ai-for-dating.html)\n",
        "\n",
        "\n",
        "\n",
        "In 2017, when a journalist asked the co-founder of Tinder how he imagined his dating app in five years’ time, Sean Rad pulled out his smartphone and pretended to have a conversation with the device.\n",
        "\n",
        "“The Tinder voice might pop up and say, ‘There’s someone down the street that we think you’re going to be attracted to, and she’s also attracted to you, and guess what, she’s free tomorrow night! And we know you both like this indie band, and it’s playing, so would you like us to buy your tickets?’”\n",
        "\n",
        "And now in 2019 — a little more than 2 years later, the prospect of algorithms finding your perfect match by compiling enormous amounts of data — from age, gender, location,  preferences  to online purchasing history and even Spotify playlists — has become very real.\n",
        "\n",
        "And AI  is progressively redefining love and making it brutally effective in various ways.\n",
        "\n",
        "\n",
        "“Algorithms can end up knowing a person better than friends, family or even themselves, and that’s revolutionizing matchmaking”, says Michal Kosinski, a computational psychologist and assistant professor at Stanford University’s Graduate School of Business. “Algorithms can learn from experiences of billions of others, while a typical person can only learn from their own experience and the experience of a relatively small number of friends.”\n",
        "\n",
        "In this blog post, we are going to be talking about a few opportunities that can be used to build an optimal dating experience and a substantial relationship in between humans down the road. (A little tbbt reference...!!)\n",
        "\n",
        "## The pipeline \n",
        "\n",
        "\n",
        "To build a relationship between human beings using technology, was never as easy as it has become. So, lets take advantage of AI methodologies that is at our disposal. But first, we need to come up with a pipeline based on which these methodologies can be deployed one after the other. \n",
        "\n",
        "\n",
        "![alt text](https://github.com/soumyadip1995/AI-for-Dating/blob/master/figs/Screenshot%20(162).png?raw=true)\n",
        "\n",
        "\n",
        "## The Description\n",
        "\n",
        "![alt text](https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/gettyimages-625496334-1537801713.jpg?resize=480:*)\n",
        "\n",
        "\n",
        "\n",
        "- For any kind of data analysis , first we need to collect data. Data from dating apps will be particularly helpful.  We need to be Looking  for image information on which we can perform image processing, swipe information, Bio information . Fortunately, we have resources.\n",
        "\n",
        "- Finding an optimal match is  crucial to find a suitable partner. If it is not right, it is not right..!!. Dating apps that are currently using AI, use information such as bio description, pictures etc very precisely to provide the user with the best possible result/match.\n",
        "\n",
        "- The next step to building a relationship is communication. We need to have  meaningful conversations in order to develop an emotional connection with the selected person. AI can help us here as well. Humans need less time swiping and more time interacting.\n",
        "\n",
        "- And finally, the one ingredient without which a proper relationship will be unsustainable is intimacy. Without intimacy,  all the above points will fall flat and we will be needing to start from square one.\n",
        "\n",
        "\n",
        "Now, granted that all the above points in the pipeline vary immensely from user to user, it is also important to realise the fact that this is the exact situation where AI can be helpful. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoBmcWoBnbDq",
        "colab_type": "text"
      },
      "source": [
        "### The Technique\n",
        "\n",
        "For this blog post, we are going to be using Machine learning, Deep Learning as well as Natural Language Processing.\n",
        "\n",
        "More Specifically, we are going to be using\n",
        "\n",
        "1)  Recommender Systems for Dating Apps. \n",
        "\n",
        "2)  Image Processing to find optimal matches\n",
        "\n",
        "3) Natural Language Processing for Connection as well as Intimacy\n",
        "\n",
        "We will be fitting the above in the pipeline that we have mentioned Previously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OBsIQ_9naGx",
        "colab_type": "text"
      },
      "source": [
        "##Recommender System and Collaborative Filtering \n",
        " \n",
        " \n",
        " We will start with a definition. A recommender system is a technology that is deployed in the environment where items (in our case other users on a dating site) are to be recommended to users or the opposite. Typically, there are many items and many users present in the environment making the problem hard and expensive to solve. This is why we have the recommender system in place.\n",
        "\n",
        "Now, before beginning with the types of recommender systems out here, we would like to consider here the possibility of hidden preferences that the users share. Users may share one or more such hidden preferences.\n",
        "\n",
        "\n",
        "1)\tOne such preference is swiping the same user. Here, the hidden preference that we are considering is where users are interacting with events. By events here, I mean Bio information, Profile Pictures, Description etc.\n",
        "\n",
        "\n",
        "2)\tAnother hidden preference that we can consider is that users are more likely to respond in the same way to similar events.\n",
        "\n",
        "\n",
        "### 2.1 Knowledge based Recommender Systems\n",
        "\n",
        "Both users and events have attributes. The more you know about your users and events, the better results can be expected.\n",
        "\n",
        "### 2.2 Content based Recommender systems\n",
        "\n",
        "\n",
        "\n",
        "Such systems are recommending items similar to those a given user has liked in the past, regardless of the preferences of other users. Basically, there are two different types of feedback. \n",
        "\n",
        "\n",
        "1) **Explicit feedback** is provided by users in form of clicking the “like”/”dislike” buttons etc. In many cases, it is hard to obtain explicit feedback data, simply because the users are not willing to provide it. Instead of clicking “dislike” for an event which the user does not consider interesting, he/she will rather leave the web page .\n",
        "\n",
        "2) **Implicit** feedback data, such as “user viewed an event”, “user swiped another user” etc , however, are often much easier to collect and can also help us to compute good recommendations. Types of implicit feedback may include:\n",
        "\n",
        " Interactions (implicit feedback):\n",
        " \n",
        "- user viewed an event\n",
        "- user viewed event’s details\n",
        "- user has reached the end of suggestions.\n",
        "\n",
        "And we can expect better performance if the feedback is good. Content based recommenders work with the past interactions of a given user and do not take other users into consideration. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 2.3 Collaborative Filtering\n",
        "\n",
        "\n",
        "We are going to be talking about a method known as **collaborative filtering**. \n",
        "Thus, here we are relying only on observed user behavior to make recommendations. Let us try to understand how collaborative filtering actually works:\n",
        "\n",
        "\n",
        "- We need to calculate the implicit or explicit rating of the user to provide a better performing recommender system . \n",
        "- So, every entry in our matrix captures a user's reaction to a given event. If a user has never rated an event, the matrix entry is zero. Often, in these type of matrices, the majority of the entries are zero. We're assuming that there's a set of features common to all of these events and events differ in how they express these features. \n",
        "- Each user has their own reaction to each feature, independent of the events. These features are hidden factors. Now, these features will transform the matrix to represent the hidden factors. \n",
        "- This process is called low-rank approximation. It's the process of compressing the Sparsity of a matrix (sparse information) into a much lower dimensional space. Then, we can calculate the rating of a given user for a given event by taking the dot product of two vectors which can be done by means of a neural network. \n",
        "-The expectation is that unknown user-to-event ratings can be approximated by dot products of corresponding feature vectors, as well. The simplest form of objective function, which we want to minimize, is:\n",
        "\n",
        "\n",
        "![alt text](https://1.bp.blogspot.com/-7MJ-z2b8AWc/W98eKyM7loI/AAAAAAAAEeo/5Ofnv5q-RU0bobKU-PPaoKPFrmOSyVDJACLcBGAs/s400/fbb1.png)\n",
        "\n",
        "\n",
        "\n",
        "*Here, r are known user-to-event ratings, and x and y are the user and event feature vectors that we are trying to find. As there are many free parameters, we need the regularization part to prevent overfitting and numerical problems, with gamma being the regularization factor*.\n",
        "\n",
        "\n",
        "### Deep Learning based Recommender System\n",
        "\n",
        "Now, with the output of the dot product of the vectors, we can represent it by the means of a neural network. We can use a weight matrix to optimize these hidden preferences and their predictions over time. We can also introduce a loss function that will determine the accuracy of our prediction. Lastly we can use gradient descent which would update our weights and minimize our loss(loss function can be implemented in many ways- least square method or MSE) and improve the prediction which in turn would update the user’s rating resulting in a highly improved recommender system. This is one of the methods and many more methods are applicable. \n",
        "\n",
        "This is one of the methods, of course there can be several more.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRWE7DWZlK6T",
        "colab_type": "text"
      },
      "source": [
        "## Computer Vision to Find Optimal Matches\n",
        "\n",
        "![alt text](http://www.thefrequentdater.com/wp-content/uploads/2016/02/tinder-match.jpg)\n",
        "\n",
        "\n",
        "\n",
        "On dating apps, men & women who have a competitive advantage in photos & texting skills will reap the highest Return Of Investment from the app. As a result, I've broken down the reward system from dating apps down to a formula, assuming we normalize message quality from a 0 to 1 scale.\n",
        "\n",
        "![alt text](https://github.com/jeffmli/TinderAutomation/raw/master/img/formula.gif)\n",
        "\n",
        "\n",
        "The better photos/good looking you are you have, the less you need to write a quality message. If you have bad photos, it doesn't matter how good your message is, nobody will respond. If you have great photos, a witty message will significantly boost your ROI. If you don't do any swiping, you'll have zero ROI. The main bottleneck here is the swipe volume and time. To solve this we can build an AI that automates tinder. We can use the Tinder API to collect data.\n",
        "\n",
        "Steps:-\n",
        "\n",
        "- We will create a huge volume of labeled dataset by swiping ourselves. As we manually swipe each profile, we will save each image to a \"like\" or a \"dislike\" profile. \n",
        "- After a few hours of swiping, we would have collected about 10,000 images, that the model can train on. This is now a Classification problem.\n",
        "- Convolutional Neural Networks have been proven to be supremely useful in handling such problems. In order to distinguish betwwn features that is \"likes\" or \"dislikes\" in our case.\n",
        "- A simple CNN built with Keras will do the trick.\n",
        "- And because our dataset is relatively small, we can train an existing model or VGG-19, trained on millions of images to leverage what it has learned previously on our own dataset and therefore improve our own predicting capability. \n",
        "- Once the CNN has learned, it can track what pipeline that we wan't and what we don't. \n",
        "- Now, all that is left to write the script that automates the entire procedure. After a few hours of running, it will send us matches after optimaztion of swipe volume(The compatible user discovery that is) and time more importantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD5meNDVuWo9",
        "colab_type": "text"
      },
      "source": [
        "##Lets take a look at some code, to prepare the data..!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo0v1GLvtb3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage import io\n",
        "from scipy import misc\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdnFJTkstm-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size = 100\n",
        "faces_in_image_limit = 1 # number of people in image. We want images of single people."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJT4ameHt2v7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_faces(img):\n",
        "    '''\n",
        "    INPUT: image argument\n",
        "    OUTPUT: \n",
        "    \n",
        "    - Will actually be using an already trained classifier to extract the faces and \n",
        "    images from the photos. Will not be building my own classifier. \n",
        "    '''\n",
        "    face_cascade = cv2.CascadeClassifier('utils/haarcascade_frontalface_alt.xml')\n",
        "    eye_cascade = cv2.CascadeClassifier('utils/haarcascade_frontalface_alt.xml')\n",
        "    imageDataFin = []\n",
        "    \n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray) #it's not extracting the faces\n",
        "    \n",
        "    for (x, y, w, h) in faces:\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        roi_color = img[y:y+h, x:x+w]\n",
        "        \n",
        "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "        \n",
        "        if len(eyes) >= 1:\n",
        "            im = resize(roi_color, (img_size, img_size))\n",
        "            imageDataFin.append(im)\n",
        "    \n",
        "    if len(imageDataFin) > faces_in_image_limit:\n",
        "        return []\n",
        "    else:\n",
        "        return imageDataFin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OR_ESBut6Wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_progress(total, current): \n",
        "    sys.stdout.write('\\rProgress: %.lf%%' % ((current/total)*100))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def folder_count(path):\n",
        "    return len([name for name in path if not name[0] ==\".\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ1JEzjYt96b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each image, we want to know if each picture is attractive or unattractive\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "data_path = 'validation'\n",
        "\n",
        "dislikes_folder_path = os.listdir(os.path.join(data_path, 'dislikes'))\n",
        "likes_folder_path = os.listdir(os.path.join(data_path, 'likes'))\n",
        "\n",
        "def process_folder(path, like_type):\n",
        "    folder_number_of_files = folder_count(path)\n",
        "    files_processed = 0\n",
        "    \n",
        "    for img in path:\n",
        "        print_progress(folder_number_of_files, files_processed)\n",
        "        if not img.startswith('.'):\n",
        "            print(img)\n",
        "            try:\n",
        "                faces = extract_faces(cv2.imread(os.path.join(data_path, os.path.join(like_type, img))))\n",
        "            except Exception:\n",
        "                print(\"Bad Image\")\n",
        "            for face in faces:\n",
        "                images.append(face)\n",
        "                if like_type == 'likes':\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    labels.append(0)\n",
        "                files_processed += 1\n",
        "        print(\"\\nProcessing of {} images complete\".format(files_processed))\n",
        "\n",
        "print(\"Processing disliked images\")\n",
        "process_folder(dislikes_folder_path, \"dislikes\")\n",
        "\n",
        "print(\"Processing liked images\")\n",
        "process_folder(likes_folder_path, \"likes\")\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(\"Image processing complete! Hurray!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYKcATfWuKAF",
        "colab_type": "text"
      },
      "source": [
        "Processing disliked images\n",
        "Progress: 0%08f78db4-a57c-4dcc-bdeb-f91ed1d4d2d1.jpg\n",
        "\n",
        "Processing of 1 images complete\n",
        "Progress: 0%0f453a88-8568-46a6-9a9b-9bf940b4bdbc.jpg\n",
        "\n",
        "Processing of 1 images complete\n",
        "Progress: 0%1080x1080_00f54f95-8d48-4936-8c73-86bc3b7daa1e.jpg\n",
        "\n",
        "Processing of 2 images complete\n",
        "Progress: 0%1080x1080_01350337-70ed-465f-a759-870c762a1e97.jpg\n",
        "\n",
        "Processing of 2 images complete\n",
        "Progress: 0%1080x1080_01648189-a95c-4658-8417-e485f433c2e2.jpg\n",
        "\n",
        "Processing of 2 images complete\n",
        "Progress: 0%1080x1080_017318c0-f4db-4422-8206-44ea36f92d77.jpg\n",
        "\n",
        "Processing of 2 images complete\n",
        "Progress: 0%1080x1080_0284a580-73dc-4349-8ada-1b73926d58e7.jpg\n",
        "\n",
        "Processing of 2 images complete\n",
        "Progress: 0%1080x1080_0318639e-9704-41ad-86cc-c31a959d4c8e.jpg\n",
        "\n",
        "Processing of 3 images complete\n",
        "Progress: 0%1080x1080_03379012-524c-40a6-9250-aaaad613ccec.jpg\n",
        "\n",
        "Processing of 3 images complete\n",
        "Progress: 0%1080x1080_043e3b6e-bca9-4c24-a6c9-667f4d25b09e.jpg\n",
        "\n",
        "Processing of 3 images complete\n",
        "Progress: 0%1080x1080_05a3b462-5409-46a6-90fc-a8323624b619.jpg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44zfb1lWuUIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_file(data, file_path_name):\n",
        "    '''\n",
        "    Takes all our data here, images and labels. Compresses images in a numpy file. \n",
        "    '''\n",
        "    print(\"Saving {}.npy\".format(file_path_name))\n",
        "    np.save(file_path_name, data)\n",
        "\n",
        "save_file(images, \"processed_val_images\")\n",
        "save_file(labels, \"processed_val_labels\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK8nqLwavCgE",
        "colab_type": "text"
      },
      "source": [
        "## Tinder CNN  implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojXYokTWvMoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from keras import applications\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML5yM16KvPr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size = 100\n",
        "_lambda = 0.01\n",
        "\n",
        "## Load Data\n",
        "\n",
        "data = np.load('processed_images.npy')\n",
        "labels = np.load('processed_labels.npy')\n",
        "\n",
        "print(data.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQfdpSn9vhLU",
        "colab_type": "text"
      },
      "source": [
        "## Train, Test and Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf-X5vbBvdrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, train_size = 0.8, random_state = 20)\n",
        "\n",
        "nb_classes = 2\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)\n",
        "\n",
        "print(\"Training label shape\", Y_train.shape)\n",
        "print(\"Testing label shape\", Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u6LIfEtvryV",
        "colab_type": "text"
      },
      "source": [
        "## VGG-19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGudQDrXvlUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_size, img_size, 3))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxAhCEqHvuHs",
        "colab_type": "text"
      },
      "source": [
        "##Layer (type) ,                     OutputShape   ,                  Param  \n",
        "=================================================================\n",
        "\n",
        "input_1 (InputLayer)         (None, 100, 100, 3)       0         \n",
        "_________________________________________________________________\n",
        "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
        "_________________________________________________________________\n",
        "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
        "_________________________________________________________________\n",
        "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
        "_________________________________________________________________\n",
        "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
        "_________________________________________________________________\n",
        "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
        "_________________________________________________________________\n",
        "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
        "_________________________________________________________________\n",
        "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
        "_________________________________________________________________\n",
        "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
        "_________________________________________________________________\n",
        "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
        "_________________________________________________________________\n",
        "block3_conv4 (Conv2D)        (None, 25, 25, 256)       590080    \n",
        "_________________________________________________________________\n",
        "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
        "_________________________________________________________________\n",
        "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
        "_________________________________________________________________\n",
        "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block4_conv4 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
        "_________________________________________________________________\n",
        "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
        "_________________________________________________________________\n",
        "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
        "_________________________________________________________________\n",
        "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
        "_________________________________________________________________\n",
        "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
        "_________________________________________________________________\n",
        "block5_conv4 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
        "_________________________________________________________________\n",
        "###block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
        "=================================================================\n",
        "\n",
        "\n",
        "Total params: 20,024,384,\n",
        "\n",
        "Trainable params: 20,024,384,\n",
        "\n",
        "Non-trainable params: 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKJ0ROwjwWl8",
        "colab_type": "text"
      },
      "source": [
        "## 3 layer Convolutional Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVMHVt1jwMVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(img_size, img_size, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "          \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "adam = optimizers.SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer= adam,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train, Y_train, \n",
        "          batch_size=64, nb_epoch=10, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6I14hTzwfxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Loss: \" + str(score[0]))\n",
        "print(\"Accuracy: \" + str(score[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l7K0ZPgwgk0",
        "colab_type": "text"
      },
      "source": [
        "Loss: 0.6892512585284442,\n",
        "\n",
        "Accuracy: 0.5798816568929063"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XduNqb7ew00k",
        "colab_type": "text"
      },
      "source": [
        "### The Script In action\n",
        "\n",
        "![alt text](https://github.com/jeffmli/TinderAutomation/raw/master/img/baetamining_bot.gif?raw=true)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byBhV5J7zYVo",
        "colab_type": "text"
      },
      "source": [
        "## Communication\n",
        "\n",
        "![alt_text](https://www.tinderseduction.com/wp-content/uploads/2016/11/tinder-enable-smart-photos.png)\n",
        "\n",
        "The Next part of our pipeline is communication. We need to make a very good first impression with our  match in order to build a relationship. For this, we will be needing Natural Language Processing:-\n",
        "\n",
        "- Dating apps are superficial in the sense that it asks users to judge based on profile pictures, Bio description etc. This makes it a little difficult to take in dating history, personality into account. \n",
        "- Thankfully, there have been studies that have been performed by various instituitions on how to incorporate optimal profiles to our own profiles. For example:- To realize if there is more than one person in the profile picture or not, user is wearing sunglasses or not, a short but wordy bio, avoid using the term \"lit\" etc.\n",
        "\n",
        "- Tinder has been using a service called Smart Photos [here](https://blog.gotinder.com/introducing-smart-photos-for-the-most-swipeworthy-you/) to create a database of  the most swipeworthy photographs  so that it can create a ranking/scoring system of the photographs based off on indiviual user's swiping pattern.\n",
        "\n",
        "![alt text](https://i1.rgstatic.net/publication/310808053_A_first_look_at_user_activity_on_tinder/links/5ab4fb0945851515f59967ef/largepreview.png)\n",
        "\n",
        "Link to the paper is [here](https://arxiv.org/pdf/1607.01952.pdf)\n",
        "\n",
        "\n",
        "\n",
        "- As far as the conversation is concerned , we can use Language models to generate more human like texts. There are language models such as BERT and OpenAI's GPT-2 model that can help us with it.\n",
        "\n",
        "- If we perform exploratory data analysis on tinder data:- such as swipe time, number of users active etc, it can be found that on  9pm on a sunday, is the best time to swipe. \n",
        "\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/750/1*0Cjj1M7shxrOGPeb3eABWQ.png)\n",
        "\n",
        "\n",
        "![alt_text](https://cdn-images-1.medium.com/max/750/1*IokQ-a4bI2-5RyXhtM8Pig.png)\n",
        "\n",
        "\n",
        "(*Sunday 9pm has the most number of swipes*)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7ioKg48MEj2",
        "colab_type": "text"
      },
      "source": [
        "###Here I have generated some text using Open AI's GPT-2 model (Pytorch Implementation) in order to carry out  conversation after you have been matched, since it is a text generator, it can generate some cool lines for you..!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fuza4n9lFfwB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "cdbe710a-92d9-4b4e-97d7-b73fd62ed63f"
      },
      "source": [
        "! git clone https://github.com/graykode/gpt-2-Pytorch "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2-Pytorch'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 117 (delta 45), reused 115 (delta 44), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (117/117), 2.38 MiB | 14.70 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7D3RwSoGevn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a2e4ed31-b329-46ac-a43d-e7e35c7c030d"
      },
      "source": [
        "% cd /content/gpt-2-Pytorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2-Pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x76WrPqsFvi9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c231c4b8-1345-425d-dc76-24864f2cf0cd"
      },
      "source": [
        "!curl --output gpt2-pytorch_model.bin https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  522M  100  522M    0     0  64.8M      0  0:00:08  0:00:08 --:--:-- 68.8M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTkA3G9xF4VG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "33c591b2-2288-4b4f-e3e7-4f8c3f1f163d"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting regex==2017.4.5 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 3.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built regex\n",
            "\u001b[31mERROR: spacy 2.0.18 has requirement regex==2018.01.10, but you'll have regex 2017.4.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: regex\n",
            "  Found existing installation: regex 2018.1.10\n",
            "    Uninstalling regex-2018.1.10:\n",
            "      Successfully uninstalled regex-2018.1.10\n",
            "Successfully installed regex-2017.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxF9kU8AGR4t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "91bcaa26-7e00-459d-b1d7-414a528244fa"
      },
      "source": [
        "! python main.py --text \"Hi, would you like to go out with me ?\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=-1, length=-1, nsamples=1, quiet=False, temperature=0.7, text='Hi, would you like to go out with me ?', top_k=40, unconditional=False)\n",
            "Hi, would you like to go out with me ?\n",
            "100% 512/512 [00:07<00:00, 67.05it/s]\n",
            "======================================== SAMPLE 1 ========================================\n",
            " Thanks!\n",
            "\n",
            "-Cody\n",
            "\n",
            "Posted on 5th January 2015 by:\n",
            "\n",
            "I'm not sure how many people know that I'm a woman, but I do know that I'd like to go out with you. I've been waiting for this interview for about 3 weeks now, and I've gotten so many requests, I've even had to try to get an interview done with you. I've only got one request: I want to meet with you in person.\n",
            "\n",
            "This is my first interview for a blog, so I'm looking forward to posting it here. For those who may not know, I'm myself a pretty big fan of a lot of women's blogs. I love them because they're so full of ideas, and they're always interesting. I've also found the most creative writing I've ever created, and I have been writing for a while now. I'm happy that I can finally share my passion with you.\n",
            "\n",
            "I know that this is no joke, but if you are an avid reader, you probably already know that I am a big fan of a lot of women's blogs. In fact, I would like to share this with you, so that you can follow along and see the beauty of my writing. I know that this is not the first time I've talked about it, but I would like to share my experience with you.\n",
            "\n",
            "I've been a blogger for quite a while now, and I'm now a big fan of an incredible range of blogs and I read a lot of them. I love all the content on them, and I'm really into all the amazing things about them. One of the things I like about them is that they're all about a different kind of person, and I don't think there's a single female blogger out there who's not passionate about what she writes about.\n",
            "\n",
            "I've always been a fan of books, which I'm not sure which I want to write about, as I read a lot of classic novels, and I don't think it's one of the things I'm interested in going to a woman's blog. But I know this is not a joke, so I'd love to share my experience with you. I know that this is a very unique kind of blogger.\n",
            "\n",
            "Let's start with the last question, and that's really important for people like me: how can I help you?\n",
            "\n",
            "I'd love to help you find a lot of content that you'll like, but I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkB0tL69MPGu",
        "colab_type": "text"
      },
      "source": [
        "## Intimacy\n",
        "\n",
        "We are now in the Final step of the Pipeline which is Intimacy. AI can  help users in communicating with their loved ones keeping in mind things like preferences. \n",
        "\n",
        "![alt text](https://technext.ng/wp-content/uploads/2017/07/loveflutter-App.jpg)\n",
        "\n",
        "A British dating app LoveFlutter helps us in doing just that. LoveFlutter uses AI that does real time analysis on messages. If it feels right, it will nudge the users to continue/meet each other if there exists signs of compatibility. \n",
        "\n",
        "There is also a dating Service called AI Matchmaker or AIMM. [Visit here](https://aimm.online/). \n",
        "\n",
        "![alt text](https://www.bangkokbankinnohub.com/wp-content/uploads/2019/02/BBL_Feb19_WorldChange_AI_Match_Maker-_2019_800x450-600x338.jpg)\n",
        "- This Dating Service uses AI right from the first Phone call to the date. It uses AI to provide personal assistance as well.\n",
        "\n",
        "- It talks to you directly to know who you are and collects data points based on that. \n",
        "- AIMM then uses Collaborative Filtering to make recommendations as you move towards your first date. \n",
        "\n",
        "- Then after the  date is over, it will collect feedback and use those data points to give you advice on whether you should continue to see each other or not. \n",
        "\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "So, you can see that AI can really transform the dating world one step at a time. The question here should be whether AI should be used to provide a better, personalized experience and the answer is yes. The one thing that human beings still do better than AI is being conscious . The idea is to allow AI into that consciousness, so that it can help us make better choices and decisions. Humans are capable of love and being loved, so why not try and enhance this power and make the world a better place to live in.  "
      ]
    }
  ]
}