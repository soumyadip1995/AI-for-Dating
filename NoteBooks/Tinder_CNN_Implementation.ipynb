{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras import applications\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Initial Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 100\n",
    "_lambda = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2953, 100, 100, 3)\n",
      "(2953,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('processed_images.npy')\n",
    "labels = np.load('processed_labels.npy')\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape (2362, 100, 100, 3)\n",
      "Testing matrix shape (591, 100, 100, 3)\n",
      "Training label shape (2362, 2)\n",
      "Testing label shape (591, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, train_size = 0.8, random_state = 20)\n",
    "\n",
    "nb_classes = 2\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print(\"Training matrix shape\", X_train.shape)\n",
    "print(\"Testing matrix shape\", X_test.shape)\n",
    "\n",
    "print(\"Training label shape\", Y_train.shape)\n",
    "print(\"Testing label shape\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google's Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 60s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.applications.inception_v3 import decode_predictions\n",
    "\n",
    "# model = InceptionV3(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16\n",
    "\n",
    "https://github.com/fchollet/deep-learning-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 17s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_size, img_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_model = Sequential()\n",
    "# top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "# top_model.add(Dense(256, activation='relu'))\n",
    "# top_model.add(Dropout(0.5))\n",
    "# top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # note that it is necessary to start with a fully-trained\n",
    "# # classifier, including the top classifier,\n",
    "# # in order to successfully do fine-tuning\n",
    "# top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# # add the model on top of the convolutional base\n",
    "# model.add(top_model)\n",
    "\n",
    "# for layer in model.layers[:25]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# # compile the model with a SGD/momentum optimizer\n",
    "# # and a very slow learning rate.\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.applications' has no attribute 'VGG14'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d546edac9ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG14\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.applications' has no attribute 'VGG14'"
     ]
    }
   ],
   "source": [
    "# model = applications.VGG14(weights = \"imagenet\", include_top=False, input_shape = (img_size, img_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_size, img_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make last two layers trainable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create FC Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = Sequential()\n",
    "\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(128, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# top_model.load_weights(\"first_try.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential() #new model\n",
    "for layer in model.layers: \n",
    "    new_model.add(layer)\n",
    "    \n",
    "new_model.add(top_model) # now this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:21]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 494s - loss: 0.7919 - acc: 0.5758\n",
      "Epoch 2/10\n",
      " - 494s - loss: 0.6826 - acc: 0.6185\n",
      "Epoch 3/10\n",
      " - 730s - loss: 0.6630 - acc: 0.6215\n",
      "Epoch 4/10\n",
      " - 2461s - loss: 0.6310 - acc: 0.6469\n",
      "Epoch 5/10\n",
      " - 2547s - loss: 0.6249 - acc: 0.6630\n",
      "Epoch 6/10\n",
      " - 2503s - loss: 0.6119 - acc: 0.6698\n",
      "Epoch 7/10\n",
      " - 2509s - loss: 0.6064 - acc: 0.6816\n",
      "Epoch 8/10\n",
      " - 2507s - loss: 0.6121 - acc: 0.6888\n",
      "Epoch 9/10\n",
      " - 2507s - loss: 0.5940 - acc: 0.6952\n",
      "Epoch 10/10\n",
      " - 2577s - loss: 0.5852 - acc: 0.7019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feafe22c400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(X_train, Y_train, \n",
    "          batch_size=64, nb_epoch=10, verbose=2 )\n",
    "\n",
    "new_model.save('model_V3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = new_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Loss: \" + str(score[0]))\n",
    "print(\"Accuracy: \" + str(score[1]))\n",
    "new_model.save('model_V3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_json = new_model.to_json()\n",
    "with open(\"newmodel.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"newmodel.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss: 0.7529 - acc: 0.5584\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.6713 - acc: 0.6029\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.6550 - acc: 0.6266\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.6436 - acc: 0.6380\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.6395 - acc: 0.6511\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.6319 - acc: 0.6600\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.6252 - acc: 0.6600\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.6218 - acc: 0.6651\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.6168 - acc: 0.6829\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.6063 - acc: 0.6914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f09e9a7e1d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten(input_shape=(img_size, img_size, 3)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "adam = optimizers.SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=64, nb_epoch=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5872958221814758\n",
      "Accuracy: 0.7394247044968323\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Loss: \" + str(score[0]))\n",
    "print(\"Accuracy: \" + str(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Layer Convolution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(100, 100,...)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 173s - loss: 0.6961 - acc: 0.5076\n",
      "Epoch 2/10\n",
      " - 47s - loss: 0.6930 - acc: 0.5148\n",
      "Epoch 3/10\n",
      " - 210s - loss: 0.6991 - acc: 0.4997\n",
      "Epoch 4/10\n",
      " - 210s - loss: 0.6961 - acc: 0.5069\n",
      "Epoch 5/10\n",
      " - 210s - loss: 0.6969 - acc: 0.4951\n",
      "Epoch 6/10\n",
      " - 210s - loss: 0.6923 - acc: 0.5247\n",
      "Epoch 7/10\n",
      " - 209s - loss: 0.6931 - acc: 0.5141\n",
      "Epoch 8/10\n",
      " - 210s - loss: 0.6931 - acc: 0.5168\n",
      "Epoch 9/10\n",
      " - 210s - loss: 0.6917 - acc: 0.5306\n",
      "Epoch 10/10\n",
      " - 209s - loss: 0.6925 - acc: 0.5148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb906876390>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "          \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "adam = optimizers.SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=64, nb_epoch=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48978227, 0.5102178 ],\n",
       "       [0.5126638 , 0.48733622],\n",
       "       [0.48950937, 0.5104906 ],\n",
       "       [0.49160662, 0.5083934 ],\n",
       "       [0.46635497, 0.533645  ],\n",
       "       [0.4912202 , 0.5087798 ],\n",
       "       [0.49160662, 0.5083934 ],\n",
       "       [0.48104823, 0.5189518 ],\n",
       "       [0.48465884, 0.5153411 ],\n",
       "       [0.50366956, 0.49633053],\n",
       "       [0.49955177, 0.5004483 ],\n",
       "       [0.49388328, 0.50611675],\n",
       "       [0.49997947, 0.5000205 ],\n",
       "       [0.48821166, 0.51178825],\n",
       "       [0.49136847, 0.5086316 ],\n",
       "       [0.47432464, 0.52567536],\n",
       "       [0.4894852 , 0.51051474],\n",
       "       [0.5095356 , 0.49046436],\n",
       "       [0.492876  , 0.507124  ],\n",
       "       [0.4995461 , 0.5004539 ],\n",
       "       [0.5097288 , 0.49027118],\n",
       "       [0.48297364, 0.51702636],\n",
       "       [0.48454112, 0.5154589 ],\n",
       "       [0.48896068, 0.5110393 ],\n",
       "       [0.49964902, 0.50035095],\n",
       "       [0.48273298, 0.51726705],\n",
       "       [0.49384546, 0.50615454],\n",
       "       [0.5086194 , 0.49138063],\n",
       "       [0.47606763, 0.52393234],\n",
       "       [0.49216706, 0.50783294],\n",
       "       [0.48908988, 0.51091015],\n",
       "       [0.50395507, 0.4960449 ],\n",
       "       [0.48264763, 0.51735246],\n",
       "       [0.503506  , 0.49649402],\n",
       "       [0.4776019 , 0.5223982 ],\n",
       "       [0.48226088, 0.5177391 ],\n",
       "       [0.47478417, 0.5252158 ],\n",
       "       [0.48579314, 0.5142068 ],\n",
       "       [0.49899307, 0.50100696],\n",
       "       [0.49896592, 0.50103414],\n",
       "       [0.5039319 , 0.49606815],\n",
       "       [0.4795824 , 0.52041763],\n",
       "       [0.48379874, 0.5162012 ],\n",
       "       [0.50983614, 0.49016392],\n",
       "       [0.50001633, 0.49998367],\n",
       "       [0.4791245 , 0.5208756 ],\n",
       "       [0.5026774 , 0.49732265],\n",
       "       [0.48896068, 0.5110393 ],\n",
       "       [0.48541874, 0.5145812 ],\n",
       "       [0.48821166, 0.51178825],\n",
       "       [0.4848079 , 0.5151921 ],\n",
       "       [0.49384546, 0.50615454],\n",
       "       [0.47894412, 0.5210558 ],\n",
       "       [0.47104624, 0.5289538 ],\n",
       "       [0.495715  , 0.50428504],\n",
       "       [0.4856408 , 0.5143592 ],\n",
       "       [0.5002527 , 0.49974722],\n",
       "       [0.49071658, 0.5092835 ],\n",
       "       [0.46512368, 0.53487635],\n",
       "       [0.48585385, 0.5141461 ],\n",
       "       [0.5026774 , 0.49732265],\n",
       "       [0.5044319 , 0.49556813],\n",
       "       [0.49577424, 0.50422573],\n",
       "       [0.5014829 , 0.4985172 ],\n",
       "       [0.50407976, 0.49592018],\n",
       "       [0.47821364, 0.52178633],\n",
       "       [0.51847166, 0.48152834],\n",
       "       [0.47758523, 0.5224148 ],\n",
       "       [0.47812214, 0.5218779 ],\n",
       "       [0.47984076, 0.52015924],\n",
       "       [0.49745792, 0.50254214],\n",
       "       [0.49170065, 0.5082993 ],\n",
       "       [0.47203374, 0.5279662 ],\n",
       "       [0.48457783, 0.51542217],\n",
       "       [0.508329  , 0.4916711 ],\n",
       "       [0.49967757, 0.5003224 ],\n",
       "       [0.4868673 , 0.51313263],\n",
       "       [0.49726972, 0.5027303 ],\n",
       "       [0.5127286 , 0.4872714 ],\n",
       "       [0.4759846 , 0.52401537],\n",
       "       [0.49655345, 0.5034466 ],\n",
       "       [0.490957  , 0.50904304],\n",
       "       [0.49283084, 0.5071692 ],\n",
       "       [0.48564386, 0.51435614],\n",
       "       [0.4997943 , 0.50020564],\n",
       "       [0.48075467, 0.51924527],\n",
       "       [0.49928954, 0.5007105 ],\n",
       "       [0.5074266 , 0.49257344],\n",
       "       [0.4888927 , 0.51110727],\n",
       "       [0.4961965 , 0.5038035 ],\n",
       "       [0.50712764, 0.4928724 ],\n",
       "       [0.49621144, 0.50378853],\n",
       "       [0.48867404, 0.5113259 ],\n",
       "       [0.4756759 , 0.52432406],\n",
       "       [0.49702987, 0.5029701 ],\n",
       "       [0.49794587, 0.50205415],\n",
       "       [0.5018134 , 0.4981866 ],\n",
       "       [0.49896592, 0.50103414],\n",
       "       [0.47653872, 0.52346134],\n",
       "       [0.5005465 , 0.49945354],\n",
       "       [0.4933072 , 0.5066928 ],\n",
       "       [0.50003636, 0.4999637 ],\n",
       "       [0.48381418, 0.5161859 ],\n",
       "       [0.49362132, 0.5063787 ],\n",
       "       [0.4989211 , 0.50107884],\n",
       "       [0.49794587, 0.50205415],\n",
       "       [0.49399406, 0.5060059 ],\n",
       "       [0.501228  , 0.498772  ],\n",
       "       [0.47763368, 0.52236634],\n",
       "       [0.4830656 , 0.51693434],\n",
       "       [0.4805012 , 0.51949877],\n",
       "       [0.49472106, 0.5052789 ],\n",
       "       [0.4947779 , 0.5052222 ],\n",
       "       [0.47856423, 0.5214358 ],\n",
       "       [0.4997945 , 0.50020546],\n",
       "       [0.49585435, 0.5041456 ],\n",
       "       [0.46635497, 0.533645  ],\n",
       "       [0.48708957, 0.5129105 ],\n",
       "       [0.4891984 , 0.51080155],\n",
       "       [0.49005556, 0.5099445 ],\n",
       "       [0.500508  , 0.49949196],\n",
       "       [0.48842865, 0.5115713 ],\n",
       "       [0.4893692 , 0.5106307 ],\n",
       "       [0.47984076, 0.52015924],\n",
       "       [0.49794587, 0.50205415],\n",
       "       [0.50371134, 0.49628866],\n",
       "       [0.48371717, 0.5162828 ],\n",
       "       [0.4942897 , 0.5057103 ],\n",
       "       [0.47869015, 0.52130985],\n",
       "       [0.49732292, 0.502677  ],\n",
       "       [0.48404706, 0.51595294],\n",
       "       [0.50215995, 0.4978401 ],\n",
       "       [0.5007432 , 0.49925682],\n",
       "       [0.49402064, 0.50597936],\n",
       "       [0.48668587, 0.5133141 ],\n",
       "       [0.5069788 , 0.4930212 ],\n",
       "       [0.4960962 , 0.50390375],\n",
       "       [0.47780183, 0.52219814],\n",
       "       [0.48348302, 0.516517  ],\n",
       "       [0.48512933, 0.5148707 ],\n",
       "       [0.5050962 , 0.49490383],\n",
       "       [0.49672174, 0.50327826],\n",
       "       [0.46938276, 0.53061724],\n",
       "       [0.49650842, 0.5034916 ],\n",
       "       [0.46138355, 0.5386165 ],\n",
       "       [0.49749103, 0.502509  ],\n",
       "       [0.49306798, 0.506932  ],\n",
       "       [0.47203374, 0.5279662 ],\n",
       "       [0.48557928, 0.51442075],\n",
       "       [0.4886678 , 0.5113322 ],\n",
       "       [0.47763368, 0.52236634],\n",
       "       [0.4954303 , 0.50456965],\n",
       "       [0.49576   , 0.50424004],\n",
       "       [0.4936357 , 0.5063643 ],\n",
       "       [0.48541874, 0.5145812 ],\n",
       "       [0.5021183 , 0.4978817 ],\n",
       "       [0.4897018 , 0.5102982 ],\n",
       "       [0.5018016 , 0.49819848],\n",
       "       [0.47606763, 0.52393234],\n",
       "       [0.4828869 , 0.5171131 ],\n",
       "       [0.4702847 , 0.5297153 ],\n",
       "       [0.48050255, 0.51949745],\n",
       "       [0.48933193, 0.5106681 ],\n",
       "       [0.5042951 , 0.49570492],\n",
       "       [0.49749184, 0.50250816],\n",
       "       [0.49820518, 0.5017948 ],\n",
       "       [0.5037254 , 0.49627462],\n",
       "       [0.49378577, 0.50621426],\n",
       "       [0.47763368, 0.52236634]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6892512585284442\n",
      "Accuracy: 0.5798816568929063\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Loss: \" + str(score[0]))\n",
    "print(\"Accuracy: \" + str(score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
